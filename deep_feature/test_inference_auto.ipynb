{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference pipeline for Deep feature **video enhancement** solution with integrated color correction solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consists of models initialization available in two ways: architecture decalration with weights loading and checkpoint load. \n",
    "\n",
    "Pipeline allows to process videos already decomposed into frame sequences: each video in separated folder. Paths perpresented in lists of corresponding folders. Pipeline reads frames, yields downscaled output, fullres guidance images and fullres result. \n",
    "\n",
    "When result is accumulated it is being written by cv2 video writer in .avi format.  \n",
    "\n",
    "**Attention:** not suitable for large videos as all data stored in RAM. For large videos rewrite pipeline for online mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.transform import rescale, resize\n",
    "import skimage.filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(growth_rate, filters, kernel_size, strides, x):\n",
    "    x = tf.keras.layers.Conv2D(growth_rate * filters, kernel_size, padding='same', strides=strides, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def dilated_conv_block(growth_rate, filters, kernel_size, dilation_rate, x):\n",
    "    x = tf.keras.layers.Conv2D(growth_rate * filters, kernel_size, padding='same', dilation_rate=dilation_rate, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_skip_block(growth_rate, filters, kernel_size, x):\n",
    "    x = tf.keras.layers.Conv2DTranspose(growth_rate * filters, kernel_size, padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(growth_rate, filters, kernel_size, strides, x):\n",
    "    x = tf.keras.layers.Conv2DTranspose(growth_rate * filters, kernel_size, padding='same', strides=strides, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 1, padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downscale_generator(height=None, width=None, input_channels=3, filters=32):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=[input_channels, height, width])\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=2, filters=filters, kernel_size=(9, 9), dilation_rate=16, x=inputs)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(5, 5), dilation_rate=8, x=x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    res1 = x\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 2, padding='same', data_format='channels_first')(x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    res2 = x\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 2, padding='same', data_format='channels_first')(x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=4, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res2])\n",
    "    x = conv_skip_block(growth_rate=4, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=2, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=2, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res1])\n",
    "    x = conv_skip_block(growth_rate=2, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=1, filters=filters, kernel_size=(3, 3), dilation_rate=1, x=x)\n",
    "    x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Subtract()([inputs, x])\n",
    "    x = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same', data_format='channels_first')(x)\n",
    "    \n",
    "    _model = tf.keras.Model(inputs=inputs, outputs=x, name='downscale_net')\n",
    "    return _model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fullres_generator(height=None, width=None, input_channels=6, filters=16):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=[input_channels, height, width])\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=2, filters=filters, kernel_size=(5, 5), dilation_rate=8, x=inputs)\n",
    "    res1 = x\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 2, padding='same', data_format='channels_first')(x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    res2 = x\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 2, padding='same', data_format='channels_first')(x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=4, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res2])\n",
    "    x = conv_skip_block(growth_rate=4, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=2, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=2, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res1])\n",
    "    x = conv_skip_block(growth_rate=2, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=1, filters=filters, kernel_size=(3, 3), dilation_rate=1, x=x)\n",
    "    x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.Subtract()([inputs[:,:3,:,:], x])\n",
    "    \n",
    "    _model = tf.keras.Model(inputs=inputs, outputs=x, name='fullres_net')\n",
    "    return _model       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model = get_downscale_generator(height=None, width=None, input_channels=3, filters=32)\n",
    "full_res_model = get_fullres_generator(height=None, width=None, input_channels=6, filters=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model_weights = r\"20210303_dilation_stack_activations_shift.hdf5\"\n",
    "full_res_model_weights = r\"20210317_full_res_shift_optimized.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model.load_weights(downscale_model_weights)\n",
    "full_res_model.load_weights(full_res_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_downscale_optimizer = tf.keras.optimizers.Adam(beta_1=0.5)\n",
    "#fake_full_ref_optimizer = tf.keras.optimizers.Adam(beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_downscaled = tf.train.Checkpoint(generator_optimizer=fake_downscale_optimizer, generator=downscale_model)\n",
    "#checkpoint_full_res = tf.train.Checkpoint(generator_optimizer=fake_full_ref_optimizer, generator=full_res_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_downscaled.restore(r\"/shared/p00536919/training_checkpoints/flare_removal/20210212-193037_flare_only_32f/ckpt-29\")\n",
    "#checkpoint_full_res.restore(r\"/shared/p00536919/training_checkpoints/flare_removal/20201127-151914/ckpt-58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_correction_generator(filters=8, data_format='channels_first'):\n",
    "    \n",
    "    axis = -3\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=[3,None,None])\n",
    "\n",
    "    out = tf.keras.layers.AvgPool2D(pool_size=(4, 8), padding='same', name='avg_pool1', data_format=data_format)(inputs)\n",
    "\n",
    "    out = tf.keras.layers.Conv2D(filters, 5, strides=4, padding='same', name='conv1', data_format=data_format)(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation1')(out)\n",
    "    out = tf.keras.layers.Conv2D(filters * 2, 3, strides=2, padding='same', name='conv2', data_format=data_format)(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation2')(out)\n",
    "    out = tf.keras.layers.Conv2D(filters * 4, 3, strides=2, padding='same', name='conv3', data_format=data_format)(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation3')(out)\n",
    "    out = tf.keras.layers.Conv2D(filters * 8, 3, strides=2, padding='same', name='conv4', data_format=data_format)(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation4')(out)\n",
    "    out = tf.expand_dims(tf.keras.layers.GlobalAveragePooling2D( data_format=data_format)(out), axis=-1)\n",
    "    out = tf.expand_dims(out, axis=-1)\n",
    "\n",
    "    out = tf.keras.layers.Conv2D(filters * 16, 1, strides=1, padding='same', name='conv5', data_format=data_format)(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation5')(out)\n",
    "    out = tf.keras.layers.Conv2D(filters * 32, 1, strides=1, padding='same', name='conv6', data_format=data_format)(out)\n",
    "   \n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation7')(out)\n",
    "   \n",
    "\n",
    "    out22 = tf.keras.layers.Flatten(name='flatten')(out)\n",
    "    \n",
    "\n",
    "    \n",
    "    out = tf.tile(tf.expand_dims(out22, axis=1), multiples=[1, 1, 1080*1920])\n",
    "\n",
    "\n",
    "    out = tf.keras.layers.Reshape((1080, 1920,filters*32))(out)\n",
    "    out = tf.transpose(out,[0,3,1,2])\n",
    "\n",
    "    bread = out\n",
    "    out = tf.keras.layers.Concatenate(axis=axis)([out, x])\n",
    "    out = tf.keras.layers.Conv2D(256*1, 1, padding='same', data_format=data_format, name='conv8')(out)\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation8')(out)\n",
    "   \n",
    "    out = tf.keras.layers.Conv2D(128, 1, padding='same', data_format=data_format, name='conv92')(out)\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation92')(out)\n",
    "    \n",
    "    out = tf.keras.layers.Conv2D(64, 1, padding='same', data_format=data_format, name='conv10')(out)\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation10')(out)\n",
    "    out = tf.keras.layers.Conv2D(32, 1, padding='same', data_format=data_format, name='conv11')(out)\n",
    "    \n",
    "    out = tf.keras.layers.LeakyReLU(name='activation100')(out)\n",
    "    out = tf.keras.layers.Conv2D(16, 1, padding='same', data_format=data_format, name='conv112')(out)\n",
    "    \n",
    "    out = tf.keras.layers.LeakyReLU(name='activation101')(out)\n",
    "    out = tf.keras.layers.Conv2D(8, 1, padding='same', data_format=data_format, name='conv1121')(out)\n",
    "\n",
    "    out = tf.keras.layers.LeakyReLU(name='activation10011')(out)\n",
    "    out = tf.keras.layers.Conv2D(4, 1, padding='same', data_format=data_format, name='conv1122')(out)\n",
    "    \n",
    "    out = tf.keras.layers.LeakyReLU(name='activation12')(out)\n",
    "    \n",
    "    out = tf.keras.layers.Conv2D(3, 1, padding='same', data_format=data_format, activation='sigmoid', name='conv14')(out)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_net = get_color_correction_generator()\n",
    "cc_net.load_weights(r'/home/p00536919/Flare_removal/Downscale_ref/log_colorcor_videodata256augmaecropnn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 1080\n",
    "IMAGE_HEIGHT = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_res_guidance(usc_downscaled_image, cnn):\n",
    "    # Paddings needed if frame size does not contain required order of \"2\"\n",
    "    paddings = tf.constant([[0,0],[0, 0], [0, 0],[0,0]])\n",
    "    padded_image = tf.cast(usc_downscaled_image[np.newaxis,:,:,:], tf.float32)\n",
    "    padded_image = tf.pad(padded_image, paddings, \"SYMMETRIC\")\n",
    "    cnn_out = cnn(tf.transpose(padded_image,[0,3,1,2]))\n",
    "    np_out = tf.transpose(cnn_out,[0,2,3,1]).numpy()[0]\n",
    "    np_out = np.clip(np_out, 0, 1)\n",
    "    np_out = cv2.resize(np_out, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation = cv2.INTER_LINEAR)\n",
    "    return np_out\n",
    "\n",
    "def get_full_res_output(image, cnn):\n",
    "    test_image = image[np.newaxis, :, :, :]\n",
    "    test_image = tf.cast(test_image, tf.float32)\n",
    "    preds = cnn(tf.transpose(test_image,[0,3,1,2]), training=True)  \n",
    "    preds = tf.transpose(preds, [0,2,3,1])\n",
    "    preds = preds.numpy()[0]\n",
    "    return preds\n",
    "\n",
    "def img_resize(image, factor=4):\n",
    "    new_img = cv2.resize(image, (IMAGE_WIDTH//factor, IMAGE_HEIGHT//factor))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USC_TEST_FOLDERS_LIST = glob.glob(r\"/shared/data1/shared/data1/Video_data_custom/1223_23/outside\"+\"/*\")\n",
    "#USC_TEST_FOLDERS_LIST = [r\"/shared/data1/VID_20200806_143342\"]\n",
    "USC_TEST_FOLDERS_LIST = [r\"/shared/data1/20210318_USC_Tablet_data/Test_data/sample_4_W/VID_20210323_170053\",\n",
    "                         r\"/shared/data1/20210318_USC_Tablet_data/Test_data/sample_4_W/VID_20210323_170453\",\n",
    "                        ]\n",
    "GT_TEST_FOLDERS_LIST =  [r\"/shared/data1/test_flare_videos/gt/VID_20200806_143508\",\n",
    "                        r\"/shared/data1/test_flare_videos/gt/VID_20200806_143559\",\n",
    "                        ]\n",
    "\n",
    "OUTPUT_FOLDER = r\"./test_output/\"\n",
    "VIDEO_OUT_FOLDER = r\"./video_out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils.utils  import dataset, image_io, image_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(OUTPUT_FOLDER)\n",
    "os.mkdir(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1422/1422 [00:00<00:00, 692556.93it/s]\n",
      "100%|██████████| 1422/1422 [00:26<00:00, 54.65it/s]\n",
      "100%|██████████| 1422/1422 [00:00<00:00, 2125.80it/s]\n",
      "100%|██████████| 1422/1422 [01:19<00:00, 17.82it/s]\n",
      "100%|██████████| 1422/1422 [00:24<00:00, 57.34it/s]\n",
      "100%|██████████| 1422/1422 [01:47<00:00, 13.21it/s]\n",
      "  0%|          | 2/1422 [00:00<01:59, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/p00536919/Flare_removal/Downscale_ref/video_out/VID_20210323_170053.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1422/1422 [01:52<00:00, 12.69it/s]\n",
      "100%|██████████| 178/178 [00:00<00:00, 416157.25it/s]\n",
      "  2%|▏         | 4/178 [00:00<00:04, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VID_20210323_170053.avi released\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:03<00:00, 50.45it/s]\n",
      "100%|██████████| 178/178 [00:00<00:00, 1991.91it/s]\n",
      "100%|██████████| 178/178 [00:09<00:00, 17.93it/s]\n",
      "100%|██████████| 178/178 [00:02<00:00, 59.96it/s]\n",
      "100%|██████████| 178/178 [00:13<00:00, 13.53it/s]\n",
      "  1%|          | 2/178 [00:00<00:13, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/p00536919/Flare_removal/Downscale_ref/video_out/VID_20210323_170453.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:13<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VID_20210323_170453.avi released\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gt_test_folder, usc_test_folder in zip(GT_TEST_FOLDERS_LIST, USC_TEST_FOLDERS_LIST):\n",
    "    \n",
    "    GT_TEST_FOLDERS = [gt_test_folder]\n",
    "    USC_TEST_FOLDERS = [usc_test_folder]\n",
    "    png_image_reader = image_io.ImageReaderPNG(transform_list=None)\n",
    "    usc_filenames = dataset.get_filenames_array(folders_list=USC_TEST_FOLDERS, images_extension='.png')\n",
    "    \n",
    "    usc_arrays = dataset.get_images_array(folders_list=USC_TEST_FOLDERS, image_reader=png_image_reader, images_extension='.png')\n",
    "    gt_arrays = dataset.get_images_array(folders_list=GT_TEST_FOLDERS, image_reader=png_image_reader, images_extension='.png')\n",
    "    \n",
    "    usc_arrays_downscaled = [img_resize(image) for image in tqdm(usc_arrays)]\n",
    "    usc_fullres_guidnance_arrays = [prepare_full_res_guidance(image, downscale_model) for image in tqdm(usc_arrays_downscaled)]\n",
    "    usc_concatenated_fullres_arrays = [np.dstack([usc_image, usc_guidance]) for \n",
    "                                       (usc_image, usc_guidance) in tqdm(list(zip(usc_arrays, usc_fullres_guidnance_arrays)))]\n",
    "    full_res_output_arrays = [get_full_res_output(image, full_res_model) for image in tqdm(usc_concatenated_fullres_arrays)] \n",
    "    full_res_output_arrays = [get_full_res_output(image, cc_net) for image in tqdm(full_res_output_arrays)]\n",
    "    \n",
    "    #for i in tqdm(list(range(len(usc_fullres_guidnance_arrays)))):\n",
    "        #plt.imsave(os.path.join(OUTPUT_FOLDER, \"{}.png\".format(str(i).zfill(4))), np.clip(full_res_output_arrays[i],0,1))\n",
    "        \n",
    "    video_name = USC_TEST_FOLDERS[0].split('/')[-1] + '.avi'\n",
    "    \n",
    "    print(os.path.join(VIDEO_OUT_FOLDER, video_name))\n",
    "    \n",
    "    out = cv2.VideoWriter(os.path.join(VIDEO_OUT_FOLDER, video_name), cv2.VideoWriter_fourcc(*'DIVX'), 24, (IMAGE_WIDTH*3, IAMGE_HEIGHT))\n",
    "    \n",
    "    for gt_image, usc_image, out_image in tqdm(list(zip(gt_arrays, usc_arrays, full_res_output_arrays))):\n",
    "        \n",
    "        \n",
    "        out_image = np.clip(out_image,0,1)\n",
    "        out_image = out_image*255\n",
    "        #out_image = cv2.resize(out_image, (1920//4, 1080//4), interpolation = cv2.INTER_LINEAR)\n",
    "        out_image = out_image.astype(np.uint8)\n",
    "        \n",
    "        usc_image = np.clip(usc_image,0,1)\n",
    "        usc_image = usc_image*255\n",
    "        #usc_image = cv2.resize(usc_image, (1080//4, 1920//4), interpolation = cv2.INTER_LINEAR)\n",
    "        usc_image = usc_image.astype(np.uint8)  \n",
    "        \n",
    "        gt_image = np.clip(gt_image,0,1)\n",
    "        gt_image = gt_image*255\n",
    "        #gt_image = cv2.resize(gt_image, (1080//4, 1920//4), interpolation = cv2.INTER_LINEAR)\n",
    "        gt_image = gt_image.astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        triple_img = np.hstack([gt_image, np.transpose(out_image[:,::-1,:],[1,0,2]), usc_image])\n",
    "        out.write(triple_img[:,:,::-1])\n",
    "        \n",
    "    out.release()\n",
    "    time.sleep(5)\n",
    "    print(\"\\n\" + video_name + r\" released\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
