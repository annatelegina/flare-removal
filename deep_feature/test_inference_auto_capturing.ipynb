{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference pipeline for Deep feature **image enhancement** solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consists of models initialization available in two ways: architecture decalration with weights loading and checkpoint load. \n",
    "\n",
    "Pipeline allows to process imagest stored in test folder. Pipeline reads images, yields downscaled output, fullres guidance images and fullres result. \n",
    "\n",
    "Fullres output images are stored in .png format.  \n",
    "\n",
    "**Attention:** not suitable for large image datasets as all data stored in RAM. For large datasets rewrite pipeline for online mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.transform import rescale, resize\n",
    "import skimage.io\n",
    "import skimage.filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(growth_rate, filters, kernel_size, strides, x):\n",
    "    x = tf.keras.layers.Conv2D(growth_rate * filters, kernel_size, padding='same', strides=strides, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def dilated_conv_block(growth_rate, filters, kernel_size, dilation_rate, x):\n",
    "    x = tf.keras.layers.Conv2D(growth_rate * filters, kernel_size, padding='same', dilation_rate=dilation_rate, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_skip_block(growth_rate, filters, kernel_size, x):\n",
    "    x = tf.keras.layers.Conv2DTranspose(growth_rate * filters, kernel_size, padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(growth_rate, filters, kernel_size, strides, x):\n",
    "    x = tf.keras.layers.Conv2DTranspose(growth_rate * filters, kernel_size, padding='same', strides=strides, data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), 1, padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downscale_generator(height=None, width=None, input_channels=3, filters=32):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=[input_channels, height, width])\n",
    "\n",
    "    x = conv_block(growth_rate=2, filters=filters, kernel_size=(5, 5), strides=1, x=inputs)\n",
    "    res1 = x\n",
    "\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=2, x=x)\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    res2 = x\n",
    "\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=2, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=2, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=8, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=16, x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=4, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res2])\n",
    "    x = conv_skip_block(growth_rate=4, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=2, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res1])\n",
    "    x = conv_skip_block(growth_rate=2, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=1, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.Subtract()([inputs[:,:3,:,:], x])\n",
    "    _model = tf.keras.Model(inputs=inputs, outputs=x, name='downscale_net')\n",
    "    return _model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fullres_generator(height=None, width=None, input_channels=6, filters=32):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=[input_channels, height, width])\n",
    "\n",
    "    x = conv_block(growth_rate=2, filters=filters, kernel_size=(5, 5), strides=1, x=inputs)\n",
    "    res1 = x\n",
    "\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=2, x=x)\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    res2 = x\n",
    "\n",
    "    x = conv_block(growth_rate=4, filters=filters, kernel_size=(3, 3), strides=2, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=2, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=4, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=8, x=x)\n",
    "    x = dilated_conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), dilation_rate=16, x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=4, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res2])\n",
    "    x = conv_skip_block(growth_rate=4, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=8, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "\n",
    "    x = deconv_block(growth_rate=2, filters=filters, kernel_size=(4, 4), strides=2, x=x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x, res1])\n",
    "    x = conv_skip_block(growth_rate=2, filters=filters, kernel_size=(1, 1), x=x)\n",
    "\n",
    "    x = conv_block(growth_rate=1, filters=filters, kernel_size=(3, 3), strides=1, x=x)\n",
    "    x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', data_format='channels_first')(x)\n",
    "    x = tf.keras.layers.Subtract()([inputs[:,:3,:,:], x])\n",
    "    _model = tf.keras.Model(inputs=inputs, outputs=x, name='fullres_net')\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model = get_downscale_generator(height=None, width=None, input_channels=3, filters=8)\n",
    "full_res_model = get_fullres_generator(height=None, width=None, input_channels=6, filters=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model_weights = r\"downscale_no_blur_smooth.hdf5\"\n",
    "full_res_model_weights = r\"fullres_no_blur.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_model.load_weights(downscale_model_weights)\n",
    "full_res_model.load_weights(full_res_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 4032\n",
    "IMAGE_HEIGHT = 3024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_res_guidance(usc_downscaled_image, cnn):\n",
    "    # Paddings needed if frame size does not contain required order of \"2\"\n",
    "    paddings = tf.constant([[0,0],[0, 2], [0, 0],[0,0]])\n",
    "    padded_image = tf.cast(usc_downscaled_image[np.newaxis,:,:,:], tf.float32)\n",
    "    padded_image = tf.pad(padded_image, paddings, \"SYMMETRIC\")\n",
    "    cnn_out = cnn(tf.transpose(padded_image,[0,3,1,2]))\n",
    "    np_out = tf.transpose(cnn_out,[0,2,3,1]).numpy()[0]\n",
    "    np_out = np.clip(np_out, 0, 1)[:-2]\n",
    "    np_out = cv2.resize(np_out, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation = cv2.INTER_LINEAR)\n",
    "    return np_out\n",
    "\n",
    "def get_full_res_output(image, cnn):\n",
    "    test_image = image[np.newaxis, :, :, :]\n",
    "    test_image = tf.cast(test_image, tf.float32)\n",
    "    preds = cnn(tf.transpose(test_image,[0,3,1,2]), training=True)  \n",
    "    preds = tf.transpose(preds, [0,2,3,1])\n",
    "    preds = preds.numpy()[0]\n",
    "    return preds\n",
    "\n",
    "def img_resize(image, factor=4):\n",
    "    new_img = cv2.resize(image, (IMAGE_WIDTH//factor, IMAGE_HEIGHT//factor))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "USC_TEST_FOLDER = r\"F:\\New_flare_removal_project\\Flare Removal\\flare - source\\00_backlit_flare\\front\"\n",
    "OUTPUT_FOLDER = r\"F:\\New_flare_removal_project\\Flare Removal\\flare - source\\00_backlit_flare\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils.utils  import dataset, image_io, image_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_image(png_image_path):\n",
    "    rgb_image_array = skimage.io.imread(png_image_path)\n",
    "    if rgb_image_array.max()>1:\n",
    "        rgb_image_array = rgb_image_array/255\n",
    "    rgb_image_array = cv2.resize(rgb_image_array, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation = cv2.INTER_LINEAR)\n",
    "    rgb_image_array = np.clip(rgb_image_array, 0,1)\n",
    "    return rgb_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:07<00:00,  1.25s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 178.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"conv2d_transpose_4\" (type Conv2DTranspose).\n\nOOM when allocating tensor with shape[1,128,1512,2016] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 256, 756, 1008), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m usc_concatenated_fullres_arrays \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdstack([usc_image, usc_guidance]) \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[0;32m     14\u001b[0m                                    (usc_image, usc_guidance) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(usc_arrays, usc_fullres_guidnance_arrays)))]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m downscale_model\n\u001b[1;32m---> 16\u001b[0m full_res_output_arrays \u001b[38;5;241m=\u001b[39m [get_full_res_output(image, full_res_model) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m tqdm(usc_concatenated_fullres_arrays)] \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(usc_fullres_guidnance_arrays)))):\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimsave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_FOLDER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m4\u001b[39m))), np\u001b[38;5;241m.\u001b[39mclip(cv2\u001b[38;5;241m.\u001b[39mresize(full_res_output_arrays[i], (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR),\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m usc_concatenated_fullres_arrays \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdstack([usc_image, usc_guidance]) \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[0;32m     14\u001b[0m                                    (usc_image, usc_guidance) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(usc_arrays, usc_fullres_guidnance_arrays)))]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m downscale_model\n\u001b[1;32m---> 16\u001b[0m full_res_output_arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mget_full_res_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_res_model\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m tqdm(usc_concatenated_fullres_arrays)] \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(usc_fullres_guidnance_arrays)))):\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimsave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_FOLDER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m4\u001b[39m))), np\u001b[38;5;241m.\u001b[39mclip(cv2\u001b[38;5;241m.\u001b[39mresize(full_res_output_arrays[i], (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR),\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mget_full_res_output\u001b[1;34m(image, cnn)\u001b[0m\n\u001b[0;32m     13\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :, :]\n\u001b[0;32m     14\u001b[0m test_image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(test_image, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 15\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \n\u001b[0;32m     16\u001b[0m preds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(preds, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf2x\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf2x\\lib\\site-packages\\keras\\backend.py:5720\u001b[0m, in \u001b[0;36mconv2d_transpose\u001b[1;34m(x, kernel, output_shape, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   5717\u001b[0m   strides \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m strides\n\u001b[0;32m   5719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dilation_rate \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m-> 5720\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5721\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5722\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5724\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m dilation_rate[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m dilation_rate[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"conv2d_transpose_4\" (type Conv2DTranspose).\n\nOOM when allocating tensor with shape[1,128,1512,2016] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 256, 756, 1008), dtype=float32)"
     ]
    }
   ],
   "source": [
    "usc_arrays = []\n",
    "\n",
    "usc_filenames = [os.path.join(USC_TEST_FOLDER, filename) for filename in os.listdir(USC_TEST_FOLDER)]\n",
    "usc_filenames.sort()\n",
    "for filename in tqdm(usc_filenames):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):            \n",
    "        usc_image = get_rgb_image(filename)\n",
    "        usc_arrays.append(usc_image)\n",
    "\n",
    "usc_arrays = np.stack(usc_arrays)\n",
    "usc_arrays_downscaled = [img_resize(image, factor=8) for image in tqdm(usc_arrays)]\n",
    "usc_fullres_guidnance_arrays = [prepare_full_res_guidance(image, downscale_model) for image in tqdm(usc_arrays_downscaled)]\n",
    "usc_concatenated_fullres_arrays = [np.dstack([usc_image, usc_guidance]) for \n",
    "                                   (usc_image, usc_guidance) in tqdm(list(zip(usc_arrays, usc_fullres_guidnance_arrays)))]\n",
    "del downscale_model\n",
    "full_res_output_arrays = [get_full_res_output(image, full_res_model) for image in tqdm(usc_concatenated_fullres_arrays)] \n",
    "for i in tqdm(list(range(len(usc_fullres_guidnance_arrays)))):\n",
    "    plt.imsave(os.path.join(OUTPUT_FOLDER, \"{}.png\".format(str(i).zfill(4))), np.clip(cv2.resize(full_res_output_arrays[i], (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation = cv2.INTER_LINEAR),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
